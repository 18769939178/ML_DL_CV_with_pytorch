# 介绍

视觉语言导航（Vision Language Navigation，VLN）是一个新兴领域，在传统的机器人导航中，需要给与一个明确的目标点（通常以坐标形式给出），然后使用规划器和驱动器完成机器人导航任务，最终到达目标点，但是在很多场景中，没办法给出一个明确的数学形式的坐标，而是会给出一些模糊的语言指令，比如说在家庭场景中给机器人一条“到达客厅中心”的命令，这种情况下，传统的导航方法就无法工作，就需要机器人在复杂环境中实现基于语言描述的导航任务，这也被称为视觉语言导航

视觉语言导航的概念，最早可能在论文[Vision-and-Language Navigation: Interpreting visually-grounded navigation instructions in real environments](https://openaccess.thecvf.com/content_cvpr_2018/html/Anderson_Vision-and-Language_Navigation_Interpreting_CVPR_2018_paper.html)中被提出，同时，此论文给出了R2R（Room to Room）数据集作为VLN的baseline，在此之前的方法，都忽视了视觉信息处理，或者说都是纯粹的语言导航问题，使用的方法是对语言进行解释或者RNN的方式来完成导航任务，并且往往会使用强化学习手段

# 历史

在VLN出现之前，也有机器人理解人类语言并且执行任务的工作，但是这个阶段，机器人理解人类指令并且执行导航任务的方法，基本上是完全基于NLP和RL手段的，哪怕会使用一些计算机视觉的方法，在手段上也会很简单，比如说识别特定物体或者地标、不同任务分开处理等，这些方法可以可以称为语言导航

但是这些方法，通常需要假定所有导航目标或待操作对象的集合都已枚举出来，并且每个目标都有标签标识，或者在视觉受限的环境中操作，需要有限的感知能力。

VLN方法会深度整合不同信息，并且可以端到端——直接从原始的视觉和语言输入中学习导航策略，来实现机器人对复杂指令和场景更好的理解

目前VLN的一个挑战是，智能体需要根据未见过的场景来解释之前的导航指令

不过，另一个VLN的问题是，难以在真实世界中进行测试，所以会使用一些模拟器来模拟真实环境，在Vision-and-Language Navigation: Interpreting visually-grounded navigation instructions in real environments这篇论文中，作者就基于Matterport3D Simulator制作出了R2R数据集

# 数据集

R2R（Room-to-Room）是一个在视觉语言导航（VLN）领域中广泛使用的数据集。以下是关于R2R数据集的详细介绍：

**R2R（Room-to-Room）数据集：**

1. **背景**：

   R2R数据集是为了研究视觉语言导航而创建的。在这个数据集中，任务是根据自然语言指令导航到目标位置。

2. **环境**：

   R2R数据集使用了Matterport3D数据集，这是一个包含大量真实室内环境的3D重建数据集。这些环境包括住宅、办公室和公共场所。

3. **指令**：

   - 数据集包含了大约21,000条自然语言导航指令，这些指令由真人为机器人编写，以指导它在3D环境中导航。
   - 每条指令都与一个导航路径相关联，该路径是由一系列的视点（即3D环境中的位置）组成的，通常遍历多个房间

4. **任务**：

   - 给定一个起始位置和一条自然语言指令，机器人的任务是找到指令中描述的目标位置。
   - 评估通常基于机器人的导航路径与人类提供的参考路径之间的差异。

5. **挑战**：

   R2R数据集提供了多种挑战，包括：

   - **语言理解**：指令可能包含复杂的描述、方向和参照物。
   - **环境感知**：机器人需要理解其周围的3D环境，并根据指令中的描述进行导航。
   - **长期规划**：导航路径可能需要机器人穿越多个房间和楼层。

6. **应用**：

   R2R数据集已经被用于许多研究，这些研究探索了如何结合视觉、语言和强化学习来解决导航任务。

R2R数据集为VLN提供了一个实际、具有挑战性的测试平台，使研究者能够开发和评估新的导航算法。