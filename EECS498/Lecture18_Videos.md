# 视频

## 概念

我们之前介绍了三维视觉，实际上三维视觉就是在二维视觉的基础上增加了一个空间维度，今天我们要讨论的视频，实际上也是这样的，不过这里增加的是一个时间维度，**视频就是一个随时间展开的图像序列**，或者说视频就是一个四维张量，两个空间维度，一个时间维度，一个通道维度

![4](./assets/4-1684474062888-88.jpg)

当然，这里的预测就复杂一些，因为传统的目标检测任务我们只需要确定单个图像中的不同对象就可以，但是在视频任务中，我们需要对动作来进行分类或者语义分割，数据集是一些带有类别标签的视频，损失函数毫无疑问就是交叉熵损失

实际上，我们在视频中识别是很有用的，我们在二维识别任务的时候，经常识别物体，但是这些都是具有某种空间范围的物体，但是在视频序列中，我们要分类的是动作或者活动，比如说游泳、跑步等等，这与二维任务有很大的区别

![6](./assets/6-1684494882587-90.jpg)

还有一点需要指出，大多数时候，在视频中我们所关心的动作实际上不仅仅是任意动作，而是人类正在执行的实际动作，所以实际上你会发现视频分类数据集的大部分视频中，大多数人都有一个类别标签，对应不同类型的动作

## 限制

但是，在视频分析中有一些限制，就是视频数据集很大，这是一个处理视频数据时候需要克服的主要限制

![8](./assets/8-1684495172396-92.jpg)

以每秒30帧的速度拍摄的视频，如果空间分辨率是640x480的话，那么每分钟会产生1.5GB的数据，这就是原始的视频数据集，如果是高清格式的1920x1080的话，一分钟的视频会是10GB大小，我们无法将如此之大的数据放入我们的GPU显存

当然也是有解决方法的，那就是我们只在一个短视频片段上进行训练，并且这个视频片段的帧率会比较低（通过采样方式），同时我们可能会使用各种下采样操作使得视频空间分辨率更低，这样就容易训练，比如说一段三五秒并且帧率为五的视频，大小可能为数百KB，或许这不是一个很好的方法，但是在计算限制的情况下，为了使得神经网络可以训练，我们不得不这样处理

## 视频分类：单帧CNN（Single-Frame CNN）

在视频分类中，"Single-Frame CNN" 是一种基于单帧图像的卷积神经网络方法， "Single-Frame" 指的是单个帧图像，也就是视频的每一帧。该方法将视频分类任务简化为对视频中每个单独帧图像进行分类，并使用单帧的特征来表示整个视频。

![12](./assets/12-1684497822536-94.jpg)

这种方法的主要思想是将视频中的每个帧图像作为独立的样本，通过单帧图像的特征提取和分类来对整个视频进行分类。通常，这个方法会使用在图像分类任务上预训练好的卷积神经网络模型（如VGG、ResNet、Inception等），将每个单帧图像输入网络中，提取图像的特征表示，然后通过全连接层或其他分类层进行视频分类。

这种方法的优点是简单直观，易于实现和理解。它适用于那些不涉及时间序列建模和动态变化的视频分类任务，例如静态场景下的动作识别或物体识别。

但是缺点是，他忽略了序列中的上下文信息