# Vision Transformer

简称ViT，实际上是注意力机制在计算机视觉中的应用，或者说带有注意力机制的计算机视觉方法

因为注意力机制实际上是一种自适应的卷积核，而CNN是固定大小的卷积核，所以注意力机制下的计算机视觉实际上就是带有了自适应感受野的卷积网络，提高了准确度的上限

# SENet

Squeeze-and-Excitation Networks，简称SENet，主要的创新是引入了注意力机制并且实现了通道之间关联性的学习，在传统的卷积神经网络（CNN）结构中，不同通道之间的特征信息是独立处理的，没有考虑到通道之间的相关性。SENet引入了一种注意力机制，使得网络可以动态地对不同通道的特征进行加权，从而更加关注重要的特征信息，抑制不重要的特征，这种特性使得网络具备更强的特征表示能力。

SENet的基本模块称为SE block，一个模块会考虑通道之间的关系并且进行学习，这个模块不仅可以用来堆叠并且构成一个SENet，还可以任意嵌入其他的网络