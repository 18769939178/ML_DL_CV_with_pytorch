# 概念

什么是**多模态（MultiModel）**呢？我们首先看一下人类交流的模式，人类之间的交流有很多模式，或者说表达自己的方式，比如说语言、声音、视觉甚至触觉等，包括语言中单词和句子的选择甚至句子背后的意图

![11-777_MMML_Fall22_L1_8](.\assets\11-777_MMML_Fall22_L1_8.png)

所以我们可以这样定义**模态（Modality）**：感知或者表达某些事物的方式；很多研究集中在感知方面，研究如何将模态整合在一起

![11-777_MMML_Fall22_L1_9](.\assets\11-777_MMML_Fall22_L1_9.png)

当然，也会有一些问题，比如说来自于一个传感器的数据，是否有真正意义上的多种模态？或者只有同一种模态的不同表达形式？我们先提出两个概念，**原始模态**和**抽象模态**，前者很接近传感器，比如说麦克风的声音信号、相机的图像数据等，然后就可以对其进行抽象，比如说将其抽象为语言（或者说使用语言描述），甚至加上语义标签（情感标签这种）等

那么什么是多模态呢？字典的定义很简单，就是多种模态，但是科学研究的定义是：对异构和互联数据的研究

![11-777_MMML_Fall22_L1_10](.\assets\11-777_MMML_Fall22_L1_10.png)

其中，异构和互联两个概念是多模态的核心，我们得搞清楚什么的数据的异构和互联

**异构（Heterogeneous）**，表示信息存在不同的表达模式，表示出不同的结构和质量，就类似于在同一个起源线上，同一侧有更多同质模态，比如说两个相机的同一个图像更加同质，两个相机的不同图像有视角差异，此外猫在不同语言中有不同的表示，而视觉和语言就有更大的差异

![11-777_MMML_Fall22_L1_11](.\assets\11-777_MMML_Fall22_L1_11.png)

当然，原始模态在本质上更加异构，抽象模态会更加抽象和简单，也会更同质

那么，我们如何去描述数据的异构呢？这里有一些在第一级看待异构性的方法，也就是考虑模式中的元素

目前，学术界已经接受这个观点：图像几乎就是一个对象列表，这是图像的近似值，可以认为这是图像的一种表示，这种表示由边界框或者感兴趣区域构成；此外我们还有一些离散化的标签表示，也因此在这个原始级别，表示完全不同

如下图所示，图像中有一些物体，图像也有对应的标题，这些模式是不同的，我们需要去描述这些差异

![11-777_MMML_Fall22_L1_13](.\assets\11-777_MMML_Fall22_L1_13.png)

![11-777_MMML_Fall22_L1_14](.\assets\11-777_MMML_Fall22_L1_14.png)

面对这种情况，学术界已经建立了一些技巧来处理这些异构数据，并且将其带入更接近的同质空间，然后进行大量扩散（diffusion），这就是基础的融合方法

此外，这些模态有不同的方式，就会有元素的不同分布，其中就有一些可能非常接近的频率或者说信息编码，并且这些元素会有结构，比如说图像有空间结构，句子有顺序结构，并且语言还有很多隐藏的结构，所以并不是所有的东西都可以看到或者将可观察的结构可视化出来，你必须考虑潜在的结构

![11-777_MMML_Fall22_L1_15](.\assets\11-777_MMML_Fall22_L1_15.png)

此外，信息是抽象的，图像可以在像素级展示，或者对象级展示，元素不止有一种表示方法，所以图像可以由其边缘或者对象表示

![11-777_MMML_Fall22_L1_16](.\assets\11-777_MMML_Fall22_L1_16.png)

同时，噪声也很重要，比如说图像存在遮挡，拼写存在错误，所以必须考虑噪声

![11-777_MMML_Fall22_L1_17](.\assets\11-777_MMML_Fall22_L1_17.png)

最后是任务的相关性，比如说我们有一个特定任务，我们想知道其中的数据到底有多么相关，或者说数据有异质模式的数据，但是如果只是有两种不同的异质模式却没有某种程度的关联，那么就会失去多模态的强大之处，然后没有关联，那么久没办法同步数据和对齐数据，如果数据真的完全独立，任务就会变得很麻烦

![11-777_MMML_Fall22_L1_18](.\assets\11-777_MMML_Fall22_L1_18.png)

所以，数据对齐是多模态中一个重要的组成部分，所以模式之间的联系是什么呢？这是一个重要的概念，在此之前我们先了解模式交互的概念

## 模态交互

我们限定一些，当我们有两种模式的时候，比如说视觉和语言，我们如何研究他们的共性呢？但是如果想研究交互，那么就需要进行某种推理或者识别

![11-777_MMML_Fall22_L1_19](.\assets\11-777_MMML_Fall22_L1_19.png)

交互只有当你对数据做某些事情的时候才会发生，比如说你使用神经网络来运行数据、得到输出，在那一刻你就开始看到数据交互了，因为这时候数据从一种模态转化为另一种模态，这是另一种类型的推理

还有一个问题就是，可以在无监督情况下进行数据交互吗？答案是不同可以，我们可以在无监督条件下研究数据共性，但是想真正研究数据融合如何相互集成的情况，就需要某种任务和推理

首先，一个模态的元素（比如说视觉方面的物体/对象）和另一种模态的元素（比如说语言上的单词），他们彼此对应，彼此等效，就比如说下图中，图片中的茶杯对应标题中的“teacup”，电脑对应“laptop”

![11-777_MMML_Fall22_L1_20](.\assets\11-777_MMML_Fall22_L1_20.png)

这里有两种方法来研究，一种是统计方式，数据驱动并且自下而上的方式，一种是语义方式，自上而下的人类知识的方式

统计方法，主要依赖数据的统计特性，如均值、方差、协方差，这种方式下，如果统计意义上相关，那么就认为彼此相关，不会考虑数据的内在语义

语义方法，主要依赖数据的语义内容，如词义、对象属性，会试图捕获不同模态之间的语义关系，而不仅仅是表面的统计关系，这种方法通常设计深入理解数据的内容、上下文和结构

![11-777_MMML_Fall22_L1_21](.\assets\11-777_MMML_Fall22_L1_21.png)



![11-777_MMML_Fall22_L1_23](.\assets\11-777_MMML_Fall22_L1_23.png)